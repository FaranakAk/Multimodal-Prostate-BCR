[fold 3] train=60 val=16 test=19
  epoch 01 | train_loss=1.5322 | val_loss=1.4200
  epoch 02 | train_loss=1.4184 | val_loss=1.3938
  epoch 03 | train_loss=1.0753 | val_loss=1.3656
  epoch 04 | train_loss=1.3190 | val_loss=1.3755
  epoch 05 | train_loss=1.5826 | val_loss=1.3766
  epoch 06 | train_loss=1.2943 | val_loss=1.3766
  epoch 07 | train_loss=1.3972 | val_loss=1.3760
  epoch 08 | train_loss=1.4219 | val_loss=1.3809
  epoch 09 | train_loss=1.4241 | val_loss=1.3887
  epoch 10 | train_loss=1.2131 | val_loss=1.4075
  epoch 11 | train_loss=1.0992 | val_loss=1.4763
  epoch 12 | train_loss=1.0621 | val_loss=1.5065
  epoch 13 | train_loss=0.6352 | val_loss=1.6111
  epoch 14 | train_loss=1.1379 | val_loss=1.6524
  epoch 15 | train_loss=0.9459 | val_loss=1.7043
  early stop.
[info] Saved ABMIL checkpoint for fold 3 to D:\OneDrive - Queen's University\Multimodal-Quiz\Multimodal-Quiz\outputs\checkpoints\abmil_full_fold3.pth
  [attn] 1003 top5 rows: [(0, 0.056918010115623474), (1, 0.05449608713388443), (2, 0.052166227251291275), (3, 0.04992666095495224), (4, 0.04777546972036362)]
  [attn] 1066 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1071 top5 rows: [(0, 0.056918010115623474), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666468024254), (4, 0.04777546972036362)]
  [attn] 1100 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1112 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666095495224), (4, 0.04777546972036362)]
  [attn] 1141 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608340859413), (2, 0.05216623470187187), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1149 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666095495224), (4, 0.04777546972036362)]
  [attn] 1174 top5 rows: [(0, 0.05691801384091377), (1, 0.05449609458446503), (2, 0.05216624215245247), (3, 0.04992666840553284), (4, 0.047775473445653915)]
  [attn] 1195 top5 rows: [(0, 0.056918010115623474), (1, 0.05449608340859413), (2, 0.05216623470187187), (3, 0.04992666468024254), (4, 0.047775473445653915)]
  [attn] 1205 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608340859413), (2, 0.05216623470187187), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1217 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608340859413), (2, 0.052166230976581573), (3, 0.04992666095495224), (4, 0.04777546599507332)]
  [attn] 1223 top5 rows: [(0, 0.056918010115623474), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666468024254), (4, 0.04777546226978302)]
  [attn] 1240 top5 rows: [(0, 0.056918010115623474), (1, 0.05449608713388443), (2, 0.05216623842716217), (3, 0.04992666468024254), (4, 0.047775473445653915)]
  [attn] 1260 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1264 top5 rows: [(0, 0.056918010115623474), (1, 0.05449609085917473), (2, 0.05216623842716217), (3, 0.04992666468024254), (4, 0.047775473445653915)]
  [attn] 1269 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1286 top5 rows: [(0, 0.05691801384091377), (1, 0.05449609085917473), (2, 0.05216624215245247), (3, 0.04992666840553284), (4, 0.04777546972036362)]
  [attn] 1291 top5 rows: [(0, 0.05691800266504288), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.04992666095495224), (4, 0.04777546972036362)]
  [attn] 1303 top5 rows: [(0, 0.056918010115623474), (1, 0.05449608713388443), (2, 0.05216623470187187), (3, 0.049926672130823135), (4, 0.047775473445653915)]
[fold 3] C-index = 0.744